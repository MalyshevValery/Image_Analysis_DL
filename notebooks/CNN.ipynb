{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import datetime\n",
    "\n",
    "import tensorflow\n",
    "%load_ext tensorboard\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../Data/'\n",
    "FRAME_PATH = DATA_PATH+'Images/'\n",
    "MASK_PATH = DATA_PATH+'Masks/'\n",
    "\n",
    "DATASET_PATH = DATA_PATH + 'Dataset/'\n",
    "\n",
    "# Create folders to hold images and masks\n",
    "folders = ['train_frames/train', 'train_masks/train', \n",
    "           'val_frames/val', 'val_masks/val', \n",
    "           'test_frames/test', 'test_masks/test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames = os.listdir(FRAME_PATH)\n",
    "all_masks = os.listdir(MASK_PATH)\n",
    "random.shuffle(all_frames)\n",
    "\n",
    "\n",
    "# Generate train, val, and test sets for frames\n",
    "\n",
    "train_split = int(0.7*len(all_frames))\n",
    "val_split = int(0.9 * len(all_frames))\n",
    "\n",
    "train_frames = all_frames[:train_split]\n",
    "val_frames = all_frames[train_split:val_split]\n",
    "test_frames = all_frames[val_split:]\n",
    "\n",
    "# Generate corresponding mask lists for masks\n",
    "\n",
    "train_masks = [f for f in all_masks if f in train_frames]\n",
    "val_masks = [f for f in all_masks if f in val_frames]\n",
    "test_masks = [f for f in all_masks if f in test_frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add train, val, test frames and masks to relevant folders\n",
    "\n",
    "\n",
    "def add_frames(dir_name, image): \n",
    "    img = Image.open(FRAME_PATH+image)\n",
    "    img.save(DATASET_PATH+'{}'.format(dir_name)+'/'+image)\n",
    "    \n",
    "def add_masks(dir_name, image):\n",
    "    img = Image.open(MASK_PATH+image)\n",
    "    img.save(DATASET_PATH+'{}'.format(dir_name)+'/'+image)\n",
    "\n",
    "    \n",
    "frame_folders = [(train_frames, 'train_frames/train'), (val_frames, 'val_frames/val'), \n",
    "                 (test_frames, 'test_frames/test')]\n",
    "\n",
    "mask_folders = [(train_masks, 'train_masks/train'), (val_masks, 'val_masks/val'), \n",
    "                (test_masks, 'test_masks/test')]\n",
    "\n",
    "# Add frames\n",
    "\n",
    "for folder in frame_folders:\n",
    "    array = folder[0]\n",
    "    name = [folder[1]] * len(array)\n",
    "\n",
    "    list(map(add_frames, name, array))\n",
    "         \n",
    "    \n",
    "# Add masks\n",
    "\n",
    "for folder in mask_folders:\n",
    "    array = folder[0]\n",
    "    name = [folder[1]] * len(array)\n",
    "    list(map(add_masks, name, array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255)\n",
    "        #shear_range=0.2,\n",
    "        #zoom_range=0.2,\n",
    "        #horizontal_flip=True)\n",
    "        \n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1992 images belonging to 1 classes.\n",
      "Found 1992 images belonging to 1 classes.\n",
      "Found 800 images belonging to 1 classes.\n",
      "Found 800 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "train_image_generator = train_datagen.flow_from_directory(DATASET_PATH + 'train_frames', batch_size = batch_size)\n",
    "train_mask_generator = train_datagen.flow_from_directory(DATASET_PATH + 'train_masks',batch_size = batch_size)\n",
    "val_image_generator = val_datagen.flow_from_directory(DATASET_PATH + 'val_frames',batch_size = batch_size)\n",
    "val_mask_generator = val_datagen.flow_from_directory(DATASET_PATH + 'val_masks',batch_size = batch_size)\n",
    "\n",
    "train_generator = zip(train_image_generator, train_mask_generator)\n",
    "val_generator = zip(val_image_generator, val_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
    " \n",
    "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(s)\n",
    "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c1)\n",
    "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    " \n",
    "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(p1)\n",
    "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    " \n",
    "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(p2)\n",
    "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    " \n",
    "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(p3)\n",
    "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    " \n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(p4)\n",
    "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c5)\n",
    " \n",
    "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(u6)\n",
    "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c6)\n",
    " \n",
    "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(u7)\n",
    "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c7)\n",
    " \n",
    "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c8)\n",
    " \n",
    "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(u9)\n",
    "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                            padding='same')(c9)\n",
    " \n",
    "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    " \n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def data_gen(img_folder, mask_folder, batch_size):\n",
    "    c = 0\n",
    "    n = os.listdir(img_folder) #List of training images\n",
    "    random.shuffle(n)\n",
    "  \n",
    "    while (True):\n",
    "        img = np.zeros((batch_size, 256, 256, 3)).astype('float')\n",
    "        mask = np.zeros((batch_size, 256, 256, 1)).astype('float')\n",
    "\n",
    "        for i in range(c, c+batch_size): #initially from 0 to 16, c = 0. \n",
    "\n",
    "            train_img = cv2.imread(img_folder+'/'+n[i])/255.\n",
    "            train_img =  cv2.resize(train_img, (256, 256))# Read an image from folder and resize\n",
    "      \n",
    "            img[i-c] = train_img #add to array - img[0], img[1], and so on.\n",
    "                                                   \n",
    "\n",
    "            train_mask = cv2.imread(mask_folder+'/'+n[i], cv2.IMREAD_GRAYSCALE)/255.\n",
    "            train_mask = cv2.resize(train_mask, (256, 256))\n",
    "            train_mask = train_mask.reshape(256, 256, 1) # Add extra dimension for parity with train_img size [512 * 512 * 3]\n",
    "\n",
    "            mask[i-c] = train_mask\n",
    "\n",
    "        c+=batch_size\n",
    "        if(c+batch_size>=len(os.listdir(img_folder))):\n",
    "            c=0\n",
    "            random.shuffle(n)\n",
    "                  # print \"randomizing again\"\n",
    "        yield img, mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_frame_path = DATASET_PATH + 'train_frames/train'\n",
    "train_mask_path = DATASET_PATH + 'train_masks/train'\n",
    "\n",
    "val_frame_path = DATASET_PATH + 'val_frames/val'\n",
    "val_mask_path = DATASET_PATH + 'val_masks/val'\n",
    "\n",
    "# Train the model\n",
    "train_gen = data_gen(train_frame_path,train_mask_path, batch_size = 4)\n",
    "val_gen = data_gen(val_frame_path,val_mask_path, batch_size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "498/498 [==============================] - 54s 108ms/step - loss: 0.1483 - acc: 0.9416 - val_loss: 0.0879 - val_acc: 0.9665\n",
      "Epoch 2/30\n",
      "498/498 [==============================] - 51s 103ms/step - loss: 0.0967 - acc: 0.9652 - val_loss: 0.0743 - val_acc: 0.9728\n",
      "Epoch 3/30\n",
      "498/498 [==============================] - 52s 105ms/step - loss: 0.0769 - acc: 0.9728 - val_loss: 0.0915 - val_acc: 0.9675\n",
      "Epoch 4/30\n",
      "498/498 [==============================] - 52s 103ms/step - loss: 0.0773 - acc: 0.9728 - val_loss: 0.0669 - val_acc: 0.9765\n",
      "Epoch 5/30\n",
      "498/498 [==============================] - 51s 103ms/step - loss: 0.0704 - acc: 0.9754 - val_loss: 0.0655 - val_acc: 0.9782\n",
      "Epoch 6/30\n",
      "498/498 [==============================] - 52s 103ms/step - loss: 0.0699 - acc: 0.9758 - val_loss: 0.0612 - val_acc: 0.9780\n",
      "Epoch 7/30\n",
      "498/498 [==============================] - 51s 102ms/step - loss: 0.0657 - acc: 0.9771 - val_loss: 0.0577 - val_acc: 0.9791\n",
      "Epoch 8/30\n",
      "498/498 [==============================] - 51s 103ms/step - loss: 0.0695 - acc: 0.9760 - val_loss: 0.0639 - val_acc: 0.9781\n",
      "Epoch 9/30\n",
      "498/498 [==============================] - 52s 104ms/step - loss: 0.0637 - acc: 0.9776 - val_loss: 0.0605 - val_acc: 0.9796\n",
      "Epoch 10/30\n",
      "498/498 [==============================] - 51s 103ms/step - loss: 0.0698 - acc: 0.9755 - val_loss: 0.0599 - val_acc: 0.9788\n",
      "Epoch 11/30\n",
      "498/498 [==============================] - 51s 102ms/step - loss: 0.0664 - acc: 0.9769 - val_loss: 0.0587 - val_acc: 0.9788\n",
      "Epoch 12/30\n",
      "498/498 [==============================] - 52s 103ms/step - loss: 0.0632 - acc: 0.9782 - val_loss: 0.0595 - val_acc: 0.9791\n",
      "Epoch 13/30\n",
      "498/498 [==============================] - 51s 103ms/step - loss: 0.0624 - acc: 0.9782 - val_loss: 0.0538 - val_acc: 0.9805\n",
      "Epoch 14/30\n",
      "498/498 [==============================] - 51s 102ms/step - loss: 0.0620 - acc: 0.9785 - val_loss: 0.0578 - val_acc: 0.9797\n",
      "Epoch 15/30\n",
      "498/498 [==============================] - 51s 103ms/step - loss: 0.0612 - acc: 0.9788 - val_loss: 0.0545 - val_acc: 0.9805\n",
      "Epoch 16/30\n",
      "498/498 [==============================] - 52s 103ms/step - loss: 0.0610 - acc: 0.9789 - val_loss: 0.0566 - val_acc: 0.9797\n",
      "Epoch 17/30\n",
      "498/498 [==============================] - 51s 103ms/step - loss: 0.0624 - acc: 0.9785 - val_loss: 0.0581 - val_acc: 0.9795\n",
      "Epoch 18/30\n",
      "498/498 [==============================] - 52s 103ms/step - loss: 0.0589 - acc: 0.9793 - val_loss: 0.0555 - val_acc: 0.9805\n",
      "Epoch 19/30\n",
      "498/498 [==============================] - 52s 104ms/step - loss: 0.0620 - acc: 0.9788 - val_loss: 0.0555 - val_acc: 0.9804\n",
      "Epoch 20/30\n",
      "498/498 [==============================] - 51s 103ms/step - loss: 0.0585 - acc: 0.9798 - val_loss: 0.0569 - val_acc: 0.9803\n",
      "Epoch 21/30\n",
      "498/498 [==============================] - 52s 104ms/step - loss: 0.0582 - acc: 0.9798 - val_loss: 0.0505 - val_acc: 0.9817\n",
      "Epoch 22/30\n",
      "498/498 [==============================] - 51s 103ms/step - loss: 0.0602 - acc: 0.9792 - val_loss: 0.0569 - val_acc: 0.9805\n",
      "Epoch 23/30\n",
      "498/498 [==============================] - 52s 103ms/step - loss: 0.0559 - acc: 0.9803 - val_loss: 0.0528 - val_acc: 0.9814\n",
      "Epoch 24/30\n",
      "498/498 [==============================] - 51s 103ms/step - loss: 0.0589 - acc: 0.9794 - val_loss: 0.0547 - val_acc: 0.9807\n",
      "Epoch 25/30\n",
      "498/498 [==============================] - 51s 103ms/step - loss: 0.0581 - acc: 0.9797 - val_loss: 0.0508 - val_acc: 0.9818\n",
      "Epoch 26/30\n",
      "498/498 [==============================] - 51s 103ms/step - loss: 0.0547 - acc: 0.9808 - val_loss: 0.0532 - val_acc: 0.9815\n",
      "Epoch 27/30\n",
      "498/498 [==============================] - 51s 103ms/step - loss: 0.0576 - acc: 0.9800 - val_loss: 0.0498 - val_acc: 0.9821\n",
      "Epoch 28/30\n",
      "498/498 [==============================] - 51s 103ms/step - loss: 0.0544 - acc: 0.9809 - val_loss: 0.0492 - val_acc: 0.9820\n",
      "Epoch 29/30\n",
      "498/498 [==============================] - 51s 103ms/step - loss: 0.0573 - acc: 0.9800 - val_loss: 0.0511 - val_acc: 0.9817\n",
      "Epoch 30/30\n",
      "498/498 [==============================] - 51s 103ms/step - loss: 0.0559 - acc: 0.9803 - val_loss: 0.0510 - val_acc: 0.9818\n"
     ]
    }
   ],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir,write_images=True)\n",
    "\n",
    "NO_OF_TRAINING_IMAGES = len(os.listdir(DATASET_PATH + 'train_frames/train'))\n",
    "NO_OF_VAL_IMAGES = len(os.listdir(DATASET_PATH + 'val_frames/val'))\n",
    "\n",
    "NO_OF_EPOCHS = 30\n",
    "\n",
    "BATCH_SIZE = batch_size\n",
    "\n",
    "weights_path = 'weigths'\n",
    "\n",
    "#opt = Adam(lr=1E-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])\n",
    "\n",
    "#checkpoint = ModelCheckpoint(weights_path, monitor='binary_crossentropy', \n",
    "#                             verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "#earlystopping = EarlyStopping(monitor = 'binary_crossentropy', verbose = 1,\n",
    "#                              min_delta = 0.01, patience = 3, mode = 'max')\n",
    "\n",
    "callbacks_list = [tensorboard_callback]#csv_logger, tbCallBack]\n",
    "\n",
    "results = model.fit_generator(train_gen, epochs=NO_OF_EPOCHS, \n",
    "                          steps_per_epoch = (NO_OF_TRAINING_IMAGES//BATCH_SIZE),\n",
    "                          validation_data=val_gen, \n",
    "                          validation_steps=(NO_OF_VAL_IMAGES//BATCH_SIZE), \n",
    "                          callbacks=callbacks_list)\n",
    "model.save('Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XRay_Segm_venv",
   "language": "python",
   "name": "xray_segm_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
